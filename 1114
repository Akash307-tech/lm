1114. import numpy as np; import matplotlib.pyplot as plt; import pandas as pd;;
data=pd.read_csv('Mall_Customers.csv') ; data.head() ;; newdata=data.iloc[:,[3,4]].values;;  import scipy.cluster.hierarchy as sch ;
dendrogram = sch.dendrogram(sch.linkage(newdata, method = 'ward')) ;  plt.title('
Dendrogram') ;plt.xlabel('Customers'); plt.ylabel('Euclidean distances') ; plt.show();;  import warnings; warnings.filterwarnings("ignore", category=FutureWarning, module="sklearn") ; warnings.filterwarnings("ignore", category=UserWarning, module="sklearn") ;; 
 from sklearn.cluster import AgglomerativeClustering; Agg_hc=AgglomerativeClustering(n_clusters=5,affinity='euclidean',linkage='ward'); 
y_hc=Agg_hc.fit_predict(newdata);; 
plt.scatter(newdata[y_hc == 0, 0], newdata[y_hc == 0, 1], s = 100, c = 'red', label = 'Cluster1');plt.scatter(newdata[y_hc == 1, 0], newdata[y_hc == 1, 1], s = 100, c = 'blue', label = 'Cluster2'); plt.scatter(newdata[y_hc == 2, 0], newdata[y_hc == 2, 1], s = 100, c = 'green', label = 'Cluster3'); plt.scatter(newdata[y_hc == 3, 0], newdata[y_hc == 3, 1], s = 100, c = 'cyan', label = 'Cluster4'); plt.scatter(newdata[y_hc == 4, 0], newdata[y_hc == 4, 1], s = 100, c = 'magenta', label = 'Cluster5'); plt.title('Clusters of customers');
plt.xlabel('Annual Income (k$)');  plt.ylabel('Spending Score (1-100)') ; plt.legend() ; plt.show()



